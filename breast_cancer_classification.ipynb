{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHq4u+ThG9R50aLy80CZpL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manali909/Breast-cancer-classification/blob/main/breast_cancer_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb0dNwMl_3T2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "df.head(10)\n",
        "df.shape\n",
        "\n",
        "sns.pairplot(df,hue = 'diagnosis', palette= 'coolwarm', vars = ['radius_mean', 'texture_mean', 'perimeter_mean','area_mean','smoothness_mean'])\n",
        "\n",
        "# count the number of empty values in each columns:\n",
        "df.isna().sum()\n",
        "\n",
        "# drop the columns with all the missing values:\n",
        "df = df.dropna(axis = 1)\n",
        "\n",
        "df.shape\n",
        "\n",
        "# Get the count of the number of Malignant(M) or Benign(B) cells\n",
        "df['diagnosis'].value_counts()\n",
        "\n",
        "# visualize the count:\n",
        "sns.countplot(df['diagnosis'], label = 'count')\n",
        "df.dtypes\n",
        "\n",
        "# Rename the diagnosis data to labels:\n",
        "df = df.rename(columns = {'diagnosis' : 'label'})\n",
        "print(df.dtypes)\n",
        "\n",
        "# define the dependent variable that need to predict(label)\n",
        "y = df['label'].values\n",
        "print(np.unique(y))\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "Y = labelencoder.fit_transform(y) # M = 1 and B = 0\n",
        "print(np.unique(Y))\n",
        "\n",
        "# define x and normalize / scale value:\n",
        "\n",
        "# define the independent variables, Drop label and ID, and normalize other data:\n",
        "X  = df.drop(labels=['label','id'],axis = 1)\n",
        "\n",
        "#scale / normalize the values to bring them into similar range:\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X)\n",
        "X = scaler.transform(X)\n",
        "\n",
        "print(X)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,Y, test_size = 0.25, random_state=42)\n",
        "print('Shape of training data is: ', x_train.shape)\n",
        "print('Shape of testing data is: ', x_test.shape)\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=30, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64,activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam' , metrics = ['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# fit with no early stopping or other callbacks:\n",
        "history = model.fit(x_train,y_train,verbose = 1,epochs = 100, batch_size = 64,validation_data = (x_test,y_test))\n",
        "\n",
        "# plot the training and validation accuracy and loss at each epochs:\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1,len(loss)+1)\n",
        "plt.plot(epochs,loss,'y',label = 'Training loss')\n",
        "plt.plot(epochs,val_loss,'r',label = 'Validation loss')\n",
        "plt.title('TechVidvan Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.plot(epochs,acc,'y',label = 'Training acc')\n",
        "plt.plot(epochs,val_acc,'r',label = 'Validation acc')\n",
        "plt.title('TechVidvan Training and Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Predicting the Test set results:\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "# Making the Confusion Matrix:\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "\n",
        "sns.heatmap(cm, annot = True)"
      ]
    }
  ]
}